{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as pl\n",
    "import torch\n",
    "from PIL import Image\n",
    "from os.path import join as pjoin \n",
    "import os\n",
    "import random\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIDVHoloDataset:\n",
    "    IMAGES_TRANSFORM = [Image.FLIP_LEFT_RIGHT, Image.FLIP_TOP_BOTTOM, Image.ROTATE_90, Image.ROTATE_180, Image.ROTATE_270]\n",
    "    def __init__(self, input_dir, transform, split_dir=\"\", split_file=\"train.txt\", only_label=None, flip_rot=True) -> None:\n",
    "        # self.input_dir = input_dir\n",
    "        self.transform = transform\n",
    "        self.labels_dict = {\"fraud/copy_without_holo\":{}, \"fraud/photo_holo_copy\":{}, \"fraud/pseudo_holo_copy\":{}, \"origins\":{}}\n",
    "        self.shorttopath = {\"copy_without_holo\":\"fraud/copy_without_holo\", \"photo_holo_copy\":\"fraud/photo_holo_copy\", \"pseudo_holo_copy\":\"fraud/pseudo_holo_copy\", \"origins\":\"origins\"}\n",
    "        self.fraud_names = [k for k in self.labels_dict if k != \"origins\"]\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        self.input_dir = os.path.normpath(input_dir)\n",
    "        self.only_label = only_label\n",
    "        for l in self.labels_dict:\n",
    "            files_tmp, labels_tmp = self.getFilesSplit(pjoin(self.input_dir, l), split_dir, split_file)\n",
    "            self.files += files_tmp\n",
    "            self.labels += labels_tmp\n",
    "        self.lenght = self.__len__()\n",
    "        self.flip_rot = flip_rot\n",
    "        if self.flip_rot:\n",
    "            print(\"random flip and rotation\")\n",
    "    \n",
    "    def randomFlipRotation(self, imgs):\n",
    "        op = random.choice(self.IMAGES_TRANSFORM)\n",
    "        return [img.transpose(op) for img in imgs]\n",
    "    \n",
    "    def getFilesSplit(self, input_dir, split_dir, split_file=\"\"):\n",
    "        images = []\n",
    "        labels = []\n",
    "        general_type = os.path.basename(input_dir)\n",
    "        if len(split_dir):\n",
    "            with open(pjoin(split_dir, self.shorttopath[general_type], split_file)) as f: #f\"train.txt\"\n",
    "                video_names = f.read().split(\"\\n\")\n",
    "        else:\n",
    "            with open(pjoin(input_dir, f\"{general_type}.lst\")) as f:\n",
    "                video_names = f.read().split(\"\\n\")[:-1]\n",
    "        for vn in video_names:\n",
    "            name = general_type if general_type == \"origins\" else \"fraud/\"+general_type\n",
    "            if self.only_label is not None:\n",
    "                # will only takes origins (only_label True) or frauds (only_label False)\n",
    "                if (general_type == \"origins\") != self.only_label:\n",
    "                    continue\n",
    "            l = f\"{name}/{os.path.dirname(vn)}\"\n",
    "            with open(pjoin(input_dir, vn)) as f:\n",
    "                tmp_lst = [v for v in f.read().split(\"\\n\") if v != \"\"]\n",
    "                images += tmp_lst\n",
    "                labels += [l] * len(tmp_lst)\n",
    "                self.labels_dict[name][l] = tmp_lst\n",
    "        assert len(images) == len(labels), \"images must be the same size as labels\"\n",
    "        return images, labels\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        f = self.files[idx]\n",
    "        l = self.labels[idx]\n",
    "        if \"origins\" in l:\n",
    "            im = Image.open(pjoin(self.input_dir, l, f))\n",
    "            tmp_l = self.labels[idx+1 if idx+1 < self.lenght else idx-1]\n",
    "            if tmp_l == l:\n",
    "                im_n = Image.open(pjoin(self.input_dir, tmp_l, self.files[idx+1 if idx+1 < self.lenght else idx-1]))\n",
    "            else:\n",
    "                im_n = Image.open(pjoin(self.input_dir, self.labels[idx-1], self.files[idx-1]))\n",
    "                    \n",
    "            if self.flip_rot and random.random() < 0.5:\n",
    "                im, im_n = self.randomFlipRotation((im, im_n))\n",
    "\n",
    "            return [self.transform(im), self.transform(im), self.transform(im_n)], l\n",
    "        else:\n",
    "            im = Image.open(pjoin(self.input_dir, l, f))\n",
    "            fraud = \"/\".join(l.split(\"/\")[:2])\n",
    "            img_path_tmp = random.choice(self.labels_dict[fraud][l])\n",
    "            im_p = Image.open(pjoin(self.input_dir, l, img_path_tmp))\n",
    "            possible_frauds = [k for k in self.fraud_names if k != fraud]\n",
    "\n",
    "            fraud_n = random.choice(possible_frauds)\n",
    "            k_n = fraud_n + \"/\"+\"/\".join(l.split(\"/\")[2:])\n",
    "            im_n = random.choice(self.labels_dict[fraud_n][k_n])\n",
    "            im_n = Image.open(pjoin(self.input_dir, k_n, im_n))\n",
    "\n",
    "            if self.flip_rot and random.random() < 0.5:\n",
    "                im, im_p, im_n = self.randomFlipRotation((im, im_p, im_n))\n",
    "\n",
    "            return [self.transform(im), self.transform(im_p), self.transform(im_n)], l\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_NORMALIZE = {\"mean\": [0.485, 0.456, 0.406], \"std\": [0.229, 0.224, 0.225]}\n",
    "\n",
    "visu_transform = T.Compose(\n",
    "    [\n",
    "        T.Resize(size=256), \n",
    "        T.RandomResizedCrop(size=(224, 224), scale=(0.8, 1)),\n",
    "        T.RandomApply(torch.nn.ModuleList([\n",
    "            T.GaussianBlur(kernel_size=[3, 11], sigma=[2, 10])]), p=0.4),\n",
    "        T.RandomApply(torch.nn.ModuleList([\n",
    "            T.ColorJitter(brightness=0.3, contrast=0.1, saturation=0.05)]), p=0.4),\n",
    "\n",
    "        # for visualization\n",
    "        # T.ToTensor(), \n",
    "        # T.Normalize(\n",
    "        #     mean=IMAGENET_NORMALIZE[\"mean\"],\n",
    "        #     std=IMAGENET_NORMALIZE[\"std\"],\n",
    "        # ),\n",
    "    ]\n",
    ")\n",
    "data_dir, split_dir = \"data/midv-holo/crop_ovds/\", \"../data/splits_kfold_s0/k0\"\n",
    "data = MIDVHoloDataset(data_dir, visu_transform, split_dir, \"trainval/train_train.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing training samples with transformations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = random.randint(0, len(data))\n",
    "pl.seed_everything(0)\n",
    "i = 4660\n",
    "ims, l = data[i]\n",
    "f, ax = plt.subplots(1, 3, figsize=(10, 4))\n",
    "f.suptitle(f\"path: {l} ({i}th image)\")\n",
    "ax[0].set_title(\"anchor img\")\n",
    "ax[0].imshow(ims[0])\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "ax[1].set_title(\"positive img\")\n",
    "ax[1].imshow(ims[1])\n",
    "ax[1].set_xticks([])\n",
    "ax[1].set_yticks([])\n",
    "ax[2].set_title(\"negative img\")\n",
    "ax[2].imshow(ims[2])\n",
    "ax[2].set_xticks([])\n",
    "ax[2].set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(6)\n",
    "n = 6\n",
    "f, ax = plt.subplots(n, 3, figsize=(7, 14))\n",
    "for j in range(n):\n",
    "    i = random.randint(0, len(data))\n",
    "    ims, l = data[i]\n",
    "    ax[j, 0].set_title(\"FAKE\" if \"fraud\" in l else \"LEGIT\")\n",
    "    ax[j, 0].imshow(ims[0])\n",
    "    ax[j, 0].set_xticks([])\n",
    "    ax[j, 0].set_yticks([])\n",
    "    # ax[j, 1].set_title(\"positive img\")\n",
    "    ax[j, 1].imshow(ims[1])\n",
    "    ax[j, 1].set_xticks([])\n",
    "    ax[j, 1].set_yticks([])\n",
    "    # ax[j, 2].set_title(\"negative img\")\n",
    "    ax[j, 2].imshow(ims[2])\n",
    "    ax[j, 2].set_xticks([])\n",
    "    ax[j, 2].set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims2, l = data[11932]\n",
    "pl.seed_everything(0)\n",
    "f, ax = plt.subplots(1, 3, figsize=(10, 4))\n",
    "f.suptitle(f\"path: {l} ({i}th image)\")\n",
    "ax[0].set_title(\"anchor img\")\n",
    "ax[0].imshow(ims2[0])\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "ax[1].set_title(\"positive img\")\n",
    "ax[1].imshow(ims2[1])\n",
    "ax[1].set_xticks([])\n",
    "ax[1].set_yticks([])\n",
    "ax[2].set_title(\"negative img\")\n",
    "ax[2].imshow(ims2[2])\n",
    "ax[2].set_xticks([])\n",
    "ax[2].set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only frauds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = MIDVHoloDataset(data_dir, visu_transform, split_dir, \"trainval/train_train.txt\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data2),len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl.seed_everything(1)\n",
    "i = random.randint(0, len(data2))\n",
    "# i = 4403\n",
    "ims2, l = data2[i]\n",
    "f, ax = plt.subplots(1, 3, figsize=(10, 4))\n",
    "f.suptitle(f\"path: {l} ({i}th image)\")\n",
    "ax[0].set_title(\"anchor img\")\n",
    "ax[0].imshow(ims2[0])\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "ax[1].set_title(\"positive img\")\n",
    "ax[1].imshow(ims2[1])\n",
    "ax[1].set_xticks([])\n",
    "ax[1].set_yticks([])\n",
    "ax[2].set_title(\"negative img\")\n",
    "ax[2].imshow(ims2[2])\n",
    "ax[2].set_xticks([])\n",
    "ax[2].set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only originals\n",
    "Used for the ablation study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_origins = MIDVHoloDataset(data_dir, visu_transform, split_dir, \"trainval/train_train.txt\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(0)\n",
    "i = random.randint(0, len(data2))\n",
    "# i = 4403\n",
    "ims2, l = data_origins[i]\n",
    "f, ax = plt.subplots(1, 3, figsize=(10, 4))\n",
    "f.suptitle(f\"path: {l} ({i}th image)\")\n",
    "ax[0].set_title(\"anchor img\")\n",
    "ax[0].imshow(ims2[0])\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "ax[1].set_title(\"positive img\")\n",
    "ax[1].imshow(ims2[1])\n",
    "ax[1].set_xticks([])\n",
    "ax[1].set_yticks([])\n",
    "ax[2].set_title(\"negative img\")\n",
    "ax[2].imshow(ims2[2])\n",
    "ax[2].set_xticks([])\n",
    "ax[2].set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No flip/rotation\n",
    "Used for the ablation study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_noflip = MIDVHoloDataset(data_dir, visu_transform, split_dir, \"trainval/train_train.txt\", flip_rot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(6)\n",
    "n = 6\n",
    "f, ax = plt.subplots(n, 3, figsize=(7, 14))\n",
    "for j in range(n):\n",
    "    i = random.randint(0, len(data_noflip))\n",
    "    ims, l = data_noflip[i]\n",
    "    ax[j, 0].set_title(\"FAKE\" if \"fraud\" in l else \"LEGIT\")\n",
    "    ax[j, 0].imshow(ims[0])\n",
    "    ax[j, 0].set_xticks([])\n",
    "    ax[j, 0].set_yticks([])\n",
    "    # ax[j, 1].set_title(\"positive img\")\n",
    "    ax[j, 1].imshow(ims[1])\n",
    "    ax[j, 1].set_xticks([])\n",
    "    ax[j, 1].set_yticks([])\n",
    "    # ax[j, 2].set_title(\"negative img\")\n",
    "    ax[j, 2].imshow(ims[2])\n",
    "    ax[j, 2].set_xticks([])\n",
    "    ax[j, 2].set_yticks([])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
